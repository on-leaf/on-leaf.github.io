---
layout: single
title:  "6.Probability and Distributions"
category: "Mathematics for Machine Learning"
tag: [Machine Learning, Artificial Intelligence, Math]
header:
  teaser: #../images/2025-07-08-CT_6/image-20250708184503610.png
toc: true
toc_sticky: true
toc_label: CONTENTS
toc_icon: "fa-solid fa-seedling" # More icons: https://fontawesome.com/v6/search?ic=free
author_profile: false
sidebar:
    nav: "counts"
search: true # Change true to false if you don't want to have this article be searched 
redirect_from:
    - /Machine Learning/MfML_12
use_math: true
---

**[Reference]** <br>
$\bullet$ [MATHEMATICS FOR MACHINE LEARNING](https://mml-book.github.io/)
{: .notice--success}

# Introduction 
{% include start-box.html class="math-box"%}
Probability is the study of uncertainty. 
Probability distributions are used as a building block for other concepts, such as probabilistic modeling, graphical models, and model selection.
In this section, we will look at:
- A probability space (the sample space, the events, and the probability of an event)
- The random variable
{% include end-box.html %}

# 1.Construction of a Probability Space
{% include start-box.html class="math-box"%}
The theory of probability aims at defining a mathematical structure to describe random outcomes of experiments.
Using this mathematical structure of probability, the goal is to perform automated reasoning, and in this sense, probability generalizes logical reasoning.

## 1-1) Philosophical Issues
Everyday reasoning and machine learning problems involve **uncertainty**, which is hard to express with simple true/false logic. 
**Probability theory** provides a mathematical framework to handle this **plausibility**, extending logic to enable **automated reasoning** under uncertainty.

In machine learning and statistics, there are two major ways to interpret probability:
- **Bayesian**: Probability represents a **degree of belief** or subjective certainty.
- **Frequentist**: Probability is the **relative frequency** of an event occurring over many trials in the long run.

Be aware that terms like "probability distribution" can sometimes be used ambiguously in machine learning literature. It's often helpful to clarify whether the context involves modeling **categorical** (discrete) or **continuous** variables.

## 1-2) Probability and Random Variables
To handle probability mathematically, we need to know the foundational framework first:
- The probability space
- A random variable

{% include start-box.html class="math-box-inner" font_size="0.9em"%}
**Probability Space**<br>
A probability space is composed of three elements to mathematically model the random outcomes of an experiment.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Sample space ($\Omega$)**<br>
The set of all possible elementary outcomes of the experiment.

Ex) (Two coin tosses): $$\Omega = \{hh, ht, th, tt\}$$
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Evnet space ($\mathcal{A}$)**<br>
A collection of events we are interested in, where each event is a subset of the sample space $\Omega$. (Technically, it must satisfy certain mathematical conditions.)

Ex) "Event of getting exactly one head" = $$\{ht, th\}$$
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Probability measure ($P$)**<br>
A function that assigns a probability $P(A)$ (a real number between 0 and 1) to each event $A \in \mathcal{A}$, representing the likelihood of that event occurring.

Ex) $$P(\{ ht, th \}) = 1/2$$
{% include end-box.html %}

Modern probability theory is based on this probability space $(\Omega, \mathcal{A}, P)$.
{% include end-box.html %}


{% include start-box.html class="math-box-inner" font_size="0.9em"%}
**Random variable**<br>
Random variable translates outcomes to numbers $X: \Omega \to \mathcal{T}$

In practice, rather than working directly with the potentially complex sample space $\Omega$, we often use a function that maps each outcome to a more convenient value (usually a number). This function is called a Random Variable $X$.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Target Space ($\mathcal{T}$)**<br>
The set of all possible values that the random variable $X$ can take (its range). 
The type of this space determines whether the random variable is discrete or continuous.
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Random Variable ($X$)**<br>
A function that maps each element $\omega$ in the sample space $\Omega$ to a specific value $X(\omega)$ in the target space $\mathcal{T}$.

Ex) Example (Counting heads in two coin tosses):
- $X(hh) = 2$
- $X(ht) = 1$
- $X(th) = 1$
- $X(tt) = 0$
- In this case, the target space is $\mathcal{T} = \{0, 1, 2\}$.

Despite its name, a random variable is neither random nor a variable; it is a **function**.
{% include end-box.html %}
{% include end-box.html %}

What we are often interested in is the probability within the target space $\mathcal{T}$. For instance, what's the probability of getting exactly one head ($P(X=1)$)?

This is linked back to the original probability space via the random variable $X$. 
The probability $P_X(S)$ of an event $S \subseteq \mathcal{T}$ in the target space is equal to the probability $P$ of the set of elements in the original sample space $\Omega$ that map to $S$ under $X$ (this set is called the pre-image $X^{-1}(S)$).

$$P_X(S) := P(X \in S) = P(X^{-1}(S)) = P(\{\omega \in \Omega \mid X(\omega) \in S\})$$

Ex) $$P_X(X=1) = P(\{ \omega \in \Omega \mid X(\omega) = 1 \}) = P(\{ ht, th \}) = 1/2$$

This function $P_X$ is called the **probability distribution** or **law** of the random variable $X$.

## 1-3) Statistics
In the following, we will look at the differences between **Probability Theory** and **Statistics**, and how they relate to Machine Learning. 
Both deal with uncertainty, but they approach it from opposite directions.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Probability Theory: Cause $\to$ Effect (Model $\to$ Data)**<br>
- Perspective: Given a probabilistic model (e.g., a fair coin), it predicts what outcomes (data) are likely to result from it.

- Process: Assumes an underlying process (model) with uncertainty and uses the rules of probability to deduce what might happen in the future.

- Example: "If I flip a fair coin 100 times, about how many heads should I expect?"
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Statistics: Effect $\to$ Cause (Data $\to$ Model)**<br>
- Perspective: Given observed results (data), it infers what underlying process (model) might have generated that data.

- Process: Starts with the observed data and tries to find the probabilistic model that best explains it.

- Example: "I flipped a coin 100 times and got 70 heads. Can I conclude the coin is fair? If not, what is the estimated probability of getting heads?"
{% include end-box.html %}

The goal of machine learning is to build a **model** that best explains and **generalizes** from given **data**. 
This is very similar to the goal of **statistics**, which infers the underlying process from observations. 
Machine learning uses the rules of probability to find the "best-fitting" model for the data.

Machine learning aims for models that perform well not just on the training data, but also on **new**, **unseen future data**. 
Analyzing and predicting this future performance (generalization ability) relies heavily on both probability and statistics.
{% include end-box.html %}


# 2.Discrete and Continuous Probabilities
{% include start-box.html class="math-box"%}
Depending on whether the target space ($\mathcal{T}$) is discrete or continuous, the natural way to refer to distributions is different.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Discrete probability**<br>
When the target space $\mathcal{T}$ is discrete, we can specify the probability that a random variable $X$ takes a particular value $x \in \mathcal{T}$.
<div class="indented-paragraph" markdown="1">
$P(X=x)$
</div>
The expression $P(X=x)$ for a discrete random variable $X$ is known as the **probability mass function** (PMF). The sum of probabilities for all possible values is 1 $\left( \sum\limits_{x \in \mathcal{T}} P(X=x) = 1 \right)$.
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Continuous probability**<br>
When the target space $\mathcal{T}$ is continuous, it is more natural to specify the probability that a random variable $X$ is in an interval.
<div class="indented-paragraph" markdown="1">
$P(a \le X \le b)$ for $a \lt b$
</div>
By convention, we specify the probaility that a random variable $X$ is less than a particular value $x$, denoted by $P(X \le x)$.
The expression $P(X \le x)$ for a continuous random variable $X$ is known as the **cumulative distribution funciton** (CDF).

The CDF $F(x)$ doesn't have a total area equal to 1; instead, its maximum value is 1.
<div class="indented-paragraph" markdown="1">
$$\lim\limits_{x \to \infty} F(x) = \lim\limits_{x \to \infty} P(X \le x) = 1$$
</div>

{% include end-box.html %}

We will use the phrase: 
- **Univariate distribution**: Refers to the probability distribution of a single random variable $X$.
- **Multivariate distribution**: Refers to the probability distribution of multiple random variables (usually represented as a vector $\vec{x}$).


## 2-1) Discrete Probabilities
When the target space is discrete, we can imagine the probability distribution of multiple random variables.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Joint probability**<br>
The probability that two random variables $X$ and $Y$ **simultaneously** take on specific values $x_i$ and $y_j$ is called the **joint probability**, denoted as $P(X=x_i, Y=y_j)$ or simply $p(x_i, y_j)$.
This is equivalent to the probability of the intersection of the two events, $P(X=x_i \cap Y=y_j)$.

<figure style="display: flex; flex-direction: column; align-items: center; margin-top: 0.5em; margin-bottom: 0.5em;">
  <img src="../images/2025-10-21-MfML_12/Fig_1.png" alt="" 
       style="width: 40%; height: auto;">
   <figcaption style="font-size: 20px; margin-top: -0.5em;">
   Fig.6.1. Visualization of a discrete bivariate probability mass function, with random variables $X$ and $Y$.
   </figcaption>
</figure> 

In the table from Figure 6.1, the value in each cell, $n_{ij}$ (or this value divided by the total count $N$), represents the joint probability. 

$$P(X=x_i, Y=y_j) = \frac{n_{ij}}{N} \tag{6.1}$$

The complete set of these joint probabilities for all possible pairs $(x_i, y_j)$ constitutes the joint **probability distribution**.
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Marginal probability**<br>
The marginal probability refers to the probability of a single random variable taking a specific value, regardless of the value of the other random variable(s).

For example, $P(X=x_i)$ is the probability that $X$ equals $x_i$, irrespective of the value of $Y$. 
It is obtained by summing the joint probabilities over all prossible valeus of $Y$ for the given $X=x_i$. 

$$P(X = x_i) = \sum_j P(X = x_i, Y = y_j)$$

In Figure 6.1, this corresponds to the sum of the $i$-th column ($c_i$).

We write $X ~ p(x)$ to denote that the random variable $X$ is distributed accroding to $p(x)$.
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Conditional probability**<br>
The conditional probability is the probability of one random variable taking a specific value **given that** another random variable has taken a specific value.

The probability of $Y=y_j$ given $X=x_i$ is denoted as $P(Y=y_j | X=x_i)$ or simply $p(y_j | x_i)$.
Conditional probability is calculated using the joint and marginal probabilities as follows:

$$P(Y=y_j | X=x_i) = \frac{P(X=x_i, Y=y_j)}{P(X=x_i)}$$

In the context of Figure 6.2, this can be interpreted as the proportion of the value in a specific cell ($n_{ij}$) relative to the sum of its column ($c_i$).
{% include end-box.html %}
These concepts of discrete probability distributions are essential for modeling **categorical variables** â€“ variables that take values from a finite set without a specific order (e.g., word occurrences in document classification, object labels in image recognition).

Joint, marginal, and conditional probabilities are fundamental tools for analyzing dependencies between variables and constructing predictive models.

## 2-2) Continuous Probabilities
Here, we will describe probabilities when a random variable can take on continuous values, such as real numbers.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Continuous random variable**<br>
A continuous random variable can take any value within a certain interval. 
<div class="indented-paragraph" markdown="1">
Ex) A person's height or the temperature of a component
</div>
Their target space $\mathcal{T}$ is typically the set of real numbers $\mathbb{R}$ or $\mathbb{R}^D$ (D-dimensional real vector space).

Handling continuous spaces requires more rigorous mathematical definitions (like measure theory, Borel $\sigma$-algebra, etc.) compared to discrete spaces, but we will focus on the core concepts here.
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Definition 6.1 (Probability Density Function, PDF)**<br>
For a continuous random variable, the probability of it taking any single specific value is zero ($P(X=x)=0$). 
Therefore, instead of defining the probability at a specific point like the PMF, we use the Probability Density Function (PDF) $f(x)$.

A function $f: \mathbb{R}^D \to \mathbb{R}$ is a PDF if it satisfies two conditions:
1. Non-negativity: $\forall \vec{x} \in \mathbb{R}^D: f(\vec{x}) \ge 0$
2. Normalization: The integral of the function over its entire domain is 1.

    $$\int_{\mathbb{R}^D} f(\vec{x}) d\vec{x} = 1 \tag{6.2}$$


The PDF itself is not a probability. However, its integral over a specific interval $[a, b]$ gives the probability that the random variable $X$ falls within that interval.

$$P(a \le X \le b) = \int_a^b f(\vec{x}) d\vec{x} \tag{6.3}$$

In essence, the PDF describes how **densely** the probability is distributed over different intervals.
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Definition 6.2 (Cumulative Distribution Function, CDF)**<br>
The Cumulative Distribution Function (CDF), $F_{\vec{X}}(\vec{x})$, is another important function for describing continuous random variables. 
The CDF represents the probability that the random variable $X$ takes a value less than or equal to a specific value $\vec{x}$.

A CDF of multivariate real-valued random variable $X$ with states $\vec{x} \in \mathbb{R}^D$ is given by

$$F_{\vec{X}}(\vec{x}) = P(X_1 \le x_1, \dots, X_D \le x_D). \tag{6.4}$$

Here, $\vec{X} = [X_1, \dots, X_D]^\top$ is the random vector, and $\vec{x} = [x_1, \dots, x_D]^\top$ is a specific vector of values.

The CDF can be expressed also as the integral of the probability density function $f(\vec{x})$ so that

$$F_{\vec{X}}(\vec{x}) = \int_{-\infty}^{x_1} \cdots \int_{-\infty}^{x_D} f(z_1, \dots, z_D) dz_1 \dots dz_D \tag{6.5}$$

Conversely, the PDF can be obtained by differentiating the CDF ($f(x) = \frac{dF(x)}{dx}$). (Note: Not all CDFs have a corresponding PDF.)
{% include end-box.html %}

{% include end-box.html %}








<div class="indented-paragraph" markdown="1">

</div>

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Definition . ()**<br>
{% include end-box.html %}


{% include start-box.html class="math-box"%}

{% include end-box.html %}