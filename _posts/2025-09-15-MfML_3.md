---
layout: single
title:  "1.Linear Algebra (3)"
category: "Mathematics for Machine Learning"
tag: [Machine Learning, Artificial Intelligence, Math]
header:
  teaser: #../images/2025-07-08-CT_6/image-20250708184503610.png
toc: true
toc_sticky: true
toc_label: CONTENTS
toc_icon: "fa-solid fa-seedling" # More icons: https://fontawesome.com/v6/search?ic=free
author_profile: false
sidebar:
    nav: "counts"
search: true # Change true to false if you don't want to have this article be searched 
redirect_from:
    - /Machine Learning/MfML_3
use_math: true
---

**[Reference]** <br>
$\bullet$ [MATHEMATICS FOR MACHINE LEARNING](https://mml-book.github.io/)
{: .notice--success}

# Introduction 
{% include start-box.html class="math-box"%}
Linear algebra is the study of vectors and certain rules to manipulate vectors.
Here, an arrow ($\rightarrow$) over letter represents a vector. 
{% include end-box.html %}

# 7. Linear Mappings
{% include start-box.html class="math-box"%}
We will study mappings on vector spaecs that preserve their structure.
<div class="indented-paragraph" markdown="1">
To define the concept of a coordinate
</div>

Consider two real vector spaces $V$,$W$.
A mapping $\Phi: V \rightarrow W$ preserves the structure of the vector space if 
$$\Phi(\vec{x}+\vec{y}) = \Phi(\vec{x}) + \Phi(\vec{y}) \tag{7.1}$$
$$\Phi(\lambda \vec{x}) = \lambda \Phi(\vec{x}) \tag{7.2}$$
for all $\vec{x}, \vec{y} \in V$ and $\lambda \in \mathbb{R}$.

We can summarize this in the following definition:

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Definition 2.15 (Linear Mapping)**<br>
For vector spaces $V,W$, a mapping $\Phi: V \rightarrow W$ is called a **_linear mapping_** (or _vector space homorphism_ / _linear transformation_) if
<center>$$\forall \vec{x}, \vec{y} \in V \forall \lambda \in \mathbb{R}: \Phi(\lambda \vec{x} + \psi \vec{y}) = \lambda \Phi(\vec{x} + \psi \Phi(\vec{y})) \tag{7.3}$$</center>
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Definition 2.16 (Injective, Surjective, Bijective)**<br>
Consider a mapping $\Phi: \mathcal{V} \rightarrow \mathcal{W}$, where $\mathcal{V}, \mathcal{W}$ can be arbitrary sets. Then $\Phi$ is called

- **_Injective_**
    <div class="indented-paragraph" markdown="1">
    if $\forall \vec{x}, \vec{y} \in \mathcal{V}: \Phi(\vec{x}) = \Phi({\vec{y}}) \Rightarrow \vec{x} = \vec{y}$
    </div>
- **_Surjective_**
    <div class="indented-paragraph" markdown="1">
    if $\Phi(\mathcal{V}) = \mathcal{W}$
    </div>
- **_Bijective_**
    <div class="indented-paragraph" markdown="1">
    if it is injective and surjective<br>There exists a mapping $\psi: \mathcal{W} \rightarrow \mathcal{V}$ which is inverse of $\Phi$, denoted by $\Phi^{-1}$
    </div>
{% include end-box.html %}

There are special cases of linear mappings between vector spaces $V$ and $W$:
- **_Isomorphism_**
    <div class="indented-paragraph" markdown="1">
    $\phi: V \rightarrow W$ linear and bijective
    </div>
- **_Endomorphism_**
    <div class="indented-paragraph" markdown="1">
    $\phi: V \rightarrow V$ linear 
    </div>
- **_Automorphism_**
    <div class="indented-paragraph" markdown="1">
    $\phi: V \rightarrow V$ linear and bijective
    </div>
- $id_{V}$
    <div class="indented-paragraph" markdown="1">
    $V \rightarrow V, x \mapsto x$: _identity mapping_ or _identity automorphism_ in $V$
    </div>

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Theorem 2.17**<br>
Finite-dimensional vector spaces $V$ and $W$ are _isomorphic_ if and only if dim($V$) = dim($W$).

It states that there exists a linear, bijective mapping between two vector spaces of the same dimension.
<div class="indented-paragraph" markdown="1">
For two vector spaces of the same dimension, they can be transformed into each other without incurring any loss
</div>
{% include end-box.html %}

## 7-1) Matrix Representation of Linear Mappings
Any $n$-dimensional vector space is isomorphic to $\mathbb{R}^n$ (Theorem 2.17).
Consider a ordered basis of $n$-dimensional vector space $V$.

$$B = (\vec{b}_1, \dots, \vec{b}_n) \tag{7.4}$$

and call this $n$-tuple an **_ordered basis_** of $V$.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
Notations for ordered/unordered basis and matrix<br>
- Ordered basis: $B = (\vec{b}_1, \dots, \vec{b}_n)$
- Unordered basis: $$\mathcal{B} = \{\vec{b}_1, \dots, \vec{b}_n \}$$
- Matrix: $[\vec{b}_1, \dots, \vec{b}_n]$ where $\vec{b}$ is column vectors
{% include end-box.html %}

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Definition 2.18 (Coordinates)**<br>
Consider a vector space $V$ and an ordered basis $B = (\vec{b}_1, \dots, \vec{b}_n)$ of $V$.
For any $x \in V$, we obtain a unique representation (linear combination)

$$\vec{x} = \alpha_1 \vec{b}_1 + \dots + \alpha_n \vec{b}_n \tag{7.5}$$

of $\vec{x}$ with respect to $B$. 
Then $\alpha_1, \dots, \alpha_n$ are the **_coordinates_** of $\vec{x}$ with repsect to $B$, and the vector

$$\vec{\alpha} = \begin{bmatrix} \alpha_1 \\ \vdots \\ \alpha_n \end{bmatrix} \in \mathbb{R}^n \tag{7.6}$$

is the **_coordinate vector_**/**_coordinate_** representation of $\vec{x}$ with respect to the ordered basis $B$.
<div class="indented-paragraph" markdown="1">
A basis defines a coordiate system!
</div>
{% include end-box.html %}

Then, let's look at connection between matrices and linear mappings between finite-dimensional vector spaces.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Definition 2.19 (Transformation Matrix)**<br>
Consider vector spaces $V, W$ with corresponding (ordered) bases $B=(\vec{b}_1, \dots, \vec{b}_n)$ and $C = (\vec{c}_1, \dots, \vec{c}_n)$.
Consider a linear mapping $\Phi: V \rightarrow W$, for $j = \in \{ 1, \dots, n \}$.

<center>$$\Phi(\vec{b}_j) = \alpha_{1j}\vec{c}_1 + \dots + \alpha_{mj}\vec{c}_m = \sum_{i=1}^{m}\alpha_{ij}\vec{c}_i \tag{7.7}$$</center>
<div class="indented-paragraph" markdown="1">
The coordinates of $$\Phi(\vec{b}_j)$$ are the $j$-th column of $A_{\Phi}$
</div>

is the unique representation of $$\Phi(\vec{b}_j)$$ with respect to $C$.
Then, we call the $m \times n$-matrix $A_{\Phi}$, whose elements are given by 

$$A_{\Phi}(i,j) = \alpha_{ij}, \tag{7.8}$$

the transformation matrix of $\Phi$ (with respect to ordered basis $B$ of $V$ and $C$ of $W$).
{% include end-box.html %}

Consider (finite-dimensional) vector spaces $V,W$ with ordered bases $B, C$ and a linear mapping $\Phi: V \rightarrow W$ with transformation matrix $A_{\Phi}$.
If $\hat{\vec{x}}$ is the coordinate vector of $\vec{x} \in V$ with respect to $B$ and $\hat{\vec{y}}$ the coordinate vector of $\vec{y} = \Phi(\vec{x}) \in W$ with respect to $C$, then 

$$\hat{\vec{y}} = A_{\Phi} \hat{\vec{x}} \tag{7.9}$$

This means that the transformation matrix can be used to map coordinates from one basis to another basis.

{% include start-box.html class="math-box-inner" font_size="0.8em"%}
**Example**<br>
Consider a homomorphisim $\Phi: V \rightarrow W$ and ordered bases $B = (\vec{b}_1, \dots, \vec{b}_n)$ of $V$ and $C = \vec{c}_1, \dots, \vec{c}_n$ of $W$. With 

$$\begin{aligned}
\Phi(b_1) &=  c_1 - c_2 + 3c_3 - c_4 \\
\Phi(b_2) &= 2c_1 + c_2 + 7c_3 + 2c_4 \\
\Phi(b_3) &= \qquad 3c_2 + c_3 + 4c_4
\end{aligned} tag{7.10}$$

the transformation matrix is can be written as $$\Phi(\vec{b}_k) = \sum_{i=1}^{4} \alpha_{ik}\vec{c}_i$$ for $k=1,\dots,3$ and is given as 

$$A_{\Phi} = [\alpha_1, \alpha_2, \alpha_3] = 
\begin{bmatrix}
 1 & 2 & 0 \\
-1 & 1 & 3 \\
 3 & 7 & 1 \\
-1 & 2 & 4
\end{bmatrix} \tag{7.11}$$
{% include end-box.html %}

## 7-2) Basis Change

{% include end-box.html %}

